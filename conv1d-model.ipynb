{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, Dropout, LSTM\nfrom sklearn.metrics import mean_absolute_error\nfrom datetime import datetime\n\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-30T22:21:51.671052Z","iopub.execute_input":"2022-03-30T22:21:51.671607Z","iopub.status.idle":"2022-03-30T22:21:59.165342Z","shell.execute_reply.started":"2022-03-30T22:21:51.671538Z","shell.execute_reply":"2022-03-30T22:21:59.164500Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Import data","metadata":{}},{"cell_type":"code","source":"crypto_df = pd.read_csv(\"../input/g-research-crypto-forecasting/train.csv\") ","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:21:59.166849Z","iopub.execute_input":"2022-03-30T22:21:59.167079Z","iopub.status.idle":"2022-03-30T22:23:13.602903Z","shell.execute_reply.started":"2022-03-30T22:21:59.167052Z","shell.execute_reply":"2022-03-30T22:23:13.602098Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"crypto_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:23:13.604682Z","iopub.execute_input":"2022-03-30T22:23:13.604956Z","iopub.status.idle":"2022-03-30T22:23:13.636410Z","shell.execute_reply.started":"2022-03-30T22:23:13.604923Z","shell.execute_reply":"2022-03-30T22:23:13.635617Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"asset_details = pd.read_csv('../input/g-research-crypto-forecasting/asset_details.csv')\nasset_details","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:23:13.637531Z","iopub.execute_input":"2022-03-30T22:23:13.637758Z","iopub.status.idle":"2022-03-30T22:23:13.660695Z","shell.execute_reply.started":"2022-03-30T22:23:13.637730Z","shell.execute_reply":"2022-03-30T22:23:13.659764Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Select Asset_ID = 6 for Ethereum\ncrypto_df = crypto_df[crypto_df[\"Asset_ID\"]==6] \ncrypto_df.info(show_counts =True)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:23:13.662506Z","iopub.execute_input":"2022-03-30T22:23:13.662720Z","iopub.status.idle":"2022-03-30T22:23:14.123579Z","shell.execute_reply.started":"2022-03-30T22:23:13.662695Z","shell.execute_reply":"2022-03-30T22:23:14.122591Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"###  Preprocessing","metadata":{}},{"cell_type":"code","source":"df = crypto_df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:23:14.124541Z","iopub.execute_input":"2022-03-30T22:23:14.124757Z","iopub.status.idle":"2022-03-30T22:23:14.187735Z","shell.execute_reply.started":"2022-03-30T22:23:14.124731Z","shell.execute_reply":"2022-03-30T22:23:14.186688Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# fill missing values \ndf = df.reindex(range(df.index[0],df.index[-1]+60,60),method='pad')\ndf = df.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:24:19.382567Z","iopub.execute_input":"2022-03-30T22:24:19.383533Z","iopub.status.idle":"2022-03-30T22:24:19.724161Z","shell.execute_reply.started":"2022-03-30T22:24:19.383487Z","shell.execute_reply":"2022-03-30T22:24:19.723198Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# rename column timestamp to Date \ndf.rename({'timestamp': 'Date'}, axis=1, inplace=True)\n\n# rename Close to Price\ndf.rename(columns={'Close': 'Price'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:24:22.901233Z","iopub.execute_input":"2022-03-30T22:24:22.902100Z","iopub.status.idle":"2022-03-30T22:24:22.910197Z","shell.execute_reply.started":"2022-03-30T22:24:22.902036Z","shell.execute_reply":"2022-03-30T22:24:22.909234Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# set index\ndf.set_index('Date', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:24:26.800704Z","iopub.execute_input":"2022-03-30T22:24:26.801660Z","iopub.status.idle":"2022-03-30T22:24:26.814748Z","shell.execute_reply.started":"2022-03-30T22:24:26.801597Z","shell.execute_reply":"2022-03-30T22:24:26.813560Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Convert to date array\ntimesteps = df.index.to_numpy()\nprices = df['Price'].to_numpy()\n\ntimesteps[:10], prices[:10]","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:24:29.679396Z","iopub.execute_input":"2022-03-30T22:24:29.680253Z","iopub.status.idle":"2022-03-30T22:24:29.689137Z","shell.execute_reply.started":"2022-03-30T22:24:29.680212Z","shell.execute_reply":"2022-03-30T22:24:29.688345Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Modeling: Conv1D","metadata":{"execution":{"iopub.status.busy":"2022-03-30T18:33:03.509971Z","iopub.execute_input":"2022-03-30T18:33:03.510329Z","iopub.status.idle":"2022-03-30T18:33:03.530227Z","shell.execute_reply.started":"2022-03-30T18:33:03.510248Z","shell.execute_reply":"2022-03-30T18:33:03.529574Z"}}},{"cell_type":"code","source":"# Create Window dataset\nHORIZON = 1      \nWINDOW_SIZE = 7 ","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:24:49.156695Z","iopub.execute_input":"2022-03-30T22:24:49.157017Z","iopub.status.idle":"2022-03-30T22:24:49.162086Z","shell.execute_reply.started":"2022-03-30T22:24:49.156985Z","shell.execute_reply":"2022-03-30T22:24:49.161094Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Create function to label windowed data\ndef get_labelled_windows(x, horizon=1):\n  \"\"\"\n  Creates labels for windowed dataset.\n  E.g. if horizon=1 (default)\n  Input: [1, 2, 3, 4, 5, 6] -> Output: ([1, 2, 3, 4, 5], [6])\n  \"\"\"\n  return x[:, :-horizon], x[:, -horizon:]","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:24:52.096096Z","iopub.execute_input":"2022-03-30T22:24:52.096391Z","iopub.status.idle":"2022-03-30T22:24:52.101312Z","shell.execute_reply.started":"2022-03-30T22:24:52.096361Z","shell.execute_reply":"2022-03-30T22:24:52.100479Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Create function to view NumPy arrays as windows\ndef make_windows(x, window_size=7, horizon=1):\n  \"\"\"\n  Turns a 1D array into a 2D array of sequential windows of window_size.\n  \"\"\"\n  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n  window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T \n  windowed_array = x[window_indexes]\n  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n\n  return windows, labels","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:25:43.006686Z","iopub.execute_input":"2022-03-30T22:25:43.007194Z","iopub.status.idle":"2022-03-30T22:25:43.013713Z","shell.execute_reply.started":"2022-03-30T22:25:43.007163Z","shell.execute_reply":"2022-03-30T22:25:43.012779Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Create function for train-test-split\ndef make_train_test_splits(windows, labels, test_split=0.2):\n  \"\"\"\n  Splits matching pairs of windows and labels into train and test splits.\n  \"\"\"\n  split_size = int(len(windows) * (1-test_split)) \n  train_windows = windows[:split_size]\n  train_labels = labels[:split_size]\n  test_windows = windows[split_size:]\n  test_labels = labels[split_size:]\n  return train_windows, test_windows, train_labels, test_labels","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:25:48.131862Z","iopub.execute_input":"2022-03-30T22:25:48.132293Z","iopub.status.idle":"2022-03-30T22:25:48.137144Z","shell.execute_reply.started":"2022-03-30T22:25:48.132247Z","shell.execute_reply":"2022-03-30T22:25:48.136492Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Test the window labelling function\ntest_window, test_label = get_labelled_windows(tf.expand_dims(tf.range(8)+1, axis=0), horizon=HORIZON)\nprint(f\"Window: {tf.squeeze(test_window).numpy()} -> Label: {tf.squeeze(test_label).numpy()}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:25:58.102382Z","iopub.execute_input":"2022-03-30T22:25:58.103264Z","iopub.status.idle":"2022-03-30T22:25:58.110916Z","shell.execute_reply.started":"2022-03-30T22:25:58.103200Z","shell.execute_reply":"2022-03-30T22:25:58.109670Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Create windowed dataset\nfull_windows, full_labels = make_windows(prices, window_size=WINDOW_SIZE, horizon=HORIZON)\nlen(full_windows), len(full_labels)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:26:01.905946Z","iopub.execute_input":"2022-03-30T22:26:01.906639Z","iopub.status.idle":"2022-03-30T22:26:01.946012Z","shell.execute_reply.started":"2022-03-30T22:26:01.906587Z","shell.execute_reply":"2022-03-30T22:26:01.945370Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_windows, test_windows, train_labels, test_labels = make_train_test_splits(full_windows, full_labels)\nlen(train_windows), len(test_windows), len(train_labels), len(test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:26:05.900757Z","iopub.execute_input":"2022-03-30T22:26:05.901251Z","iopub.status.idle":"2022-03-30T22:26:05.906693Z","shell.execute_reply.started":"2022-03-30T22:26:05.901219Z","shell.execute_reply":"2022-03-30T22:26:05.906162Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Check data sample shapes\ntrain_windows[0].shape # returns (WINDOW_SIZE, )","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:26:09.758991Z","iopub.execute_input":"2022-03-30T22:26:09.759482Z","iopub.status.idle":"2022-03-30T22:26:09.764866Z","shell.execute_reply.started":"2022-03-30T22:26:09.759424Z","shell.execute_reply":"2022-03-30T22:26:09.764061Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:26:14.147746Z","iopub.execute_input":"2022-03-30T22:26:14.148725Z","iopub.status.idle":"2022-03-30T22:26:14.153545Z","shell.execute_reply.started":"2022-03-30T22:26:14.148676Z","shell.execute_reply":"2022-03-30T22:26:14.152635Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Before we pass our data to the Conv1D layer, we have to reshape it in order to make sure it works\nx = tf.constant(train_windows[0])\nexpand_dims_layer = layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) # add an extra dimension for timesteps\nprint(f\"Original shape: {x.shape}\") # (WINDOW_SIZE)\nprint(f\"Expanded shape: {expand_dims_layer(x).shape}\") # (WINDOW_SIZE, input_dim) \nprint(f\"Original values with expanded shape:\\n {expand_dims_layer(x)}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:26:22.294218Z","iopub.execute_input":"2022-03-30T22:26:22.294833Z","iopub.status.idle":"2022-03-30T22:26:22.332234Z","shell.execute_reply.started":"2022-03-30T22:26:22.294795Z","shell.execute_reply":"2022-03-30T22:26:22.331566Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Create model callbacks\nimport os\n\n# Create a function to implement a ModelCheckpoint callback with a specific filename \ndef create_model_checkpoint(model_name, save_path=\"model_experiments\"):\n  return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_path, model_name), # create filepath to save model\n                                            verbose=0,                                    # only output a limited amount of text\n                                            save_best_only=True)                          # save only the best model to file","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:26:29.054093Z","iopub.execute_input":"2022-03-30T22:26:29.054451Z","iopub.status.idle":"2022-03-30T22:26:29.060044Z","shell.execute_reply.started":"2022-03-30T22:26:29.054415Z","shell.execute_reply":"2022-03-30T22:26:29.059007Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(42)\n\n# Create model\nconv1D_model = tf.keras.Sequential([\n  # Create Lambda layer to reshape inputs, without this layer, the model will error\n  layers.Lambda(lambda x: tf.expand_dims(x, axis=1)), # resize the inputs to adjust for window size / Conv1D 3D input requirements\n  layers.Conv1D(filters=128, kernel_size=5, padding=\"causal\", activation=\"relu\"),\n  layers.Dense(HORIZON)\n], name=\"model_4_conv1D\")\n\n# Compile model\nconv1D_model.compile(loss=\"mae\",\n                optimizer=tf.keras.optimizers.Adam())\n\n# Fit model\nconv1D_model.fit(train_windows,\n            train_labels,\n            batch_size=128, \n            epochs=100,\n            verbose=0,\n            validation_data=(test_windows, test_labels),\n            callbacks=[create_model_checkpoint(model_name=conv1D_model.name)])","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:29:46.540686Z","iopub.execute_input":"2022-03-30T22:29:46.541510Z","iopub.status.idle":"2022-03-30T22:40:31.373628Z","shell.execute_reply.started":"2022-03-30T22:29:46.541467Z","shell.execute_reply":"2022-03-30T22:40:31.372360Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"conv1D_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:40:31.376039Z","iopub.execute_input":"2022-03-30T22:40:31.376416Z","iopub.status.idle":"2022-03-30T22:40:31.386639Z","shell.execute_reply.started":"2022-03-30T22:40:31.376368Z","shell.execute_reply":"2022-03-30T22:40:31.385612Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Load in best performing Conv1D model and evaluate it on the test data\nconv1D_model = tf.keras.models.load_model(\"model_experiments/model_4_conv1D\")\nconv1D_model.evaluate(test_windows, test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:40:31.388447Z","iopub.execute_input":"2022-03-30T22:40:31.389075Z","iopub.status.idle":"2022-03-30T22:40:35.376342Z","shell.execute_reply.started":"2022-03-30T22:40:31.389029Z","shell.execute_reply":"2022-03-30T22:40:35.375377Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Function for forecasting on the test dataset\ndef make_preds(model, input_data):\n  \"\"\"\n  Uses model to make predictions on input_data.\n\n  Parameters\n  ----------\n       model: trained model \n  input_data: windowed input data (same kind of data model was trained on)\n\n  Returns model predictions on input_data.\n  \"\"\"\n  forecast = model.predict(input_data)\n  # return 1D array of predictions  \n  return tf.squeeze(forecast)         ","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:40:35.378914Z","iopub.execute_input":"2022-03-30T22:40:35.379238Z","iopub.status.idle":"2022-03-30T22:40:35.384732Z","shell.execute_reply.started":"2022-03-30T22:40:35.379193Z","shell.execute_reply":"2022-03-30T22:40:35.383732Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Function to evaluate prediction\ndef evaluate_preds(y_true, y_pred):\n  # Make sure float32 (for metric calculations)\n  y_true = tf.cast(y_true, dtype=tf.float32)\n  y_pred = tf.cast(y_pred, dtype=tf.float32)\n\n  # Calculate various metrics\n  mae = tf.keras.metrics.mean_absolute_error(y_true, y_pred)\n  mse = tf.keras.metrics.mean_squared_error(y_true, y_pred)\n  rmse = tf.sqrt(mse)\n  mape = tf.keras.metrics.mean_absolute_percentage_error(y_true, y_pred)\n  mase = mean_absolute_scaled_error(y_true, y_pred)\n  \n  return {\"mae\": mae.numpy(),\n          \"mse\": mse.numpy(),\n          \"rmse\": rmse.numpy(),\n          \"mape\": mape.numpy()}","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:50:26.815726Z","iopub.execute_input":"2022-03-30T22:50:26.816084Z","iopub.status.idle":"2022-03-30T22:50:26.822857Z","shell.execute_reply.started":"2022-03-30T22:50:26.816047Z","shell.execute_reply":"2022-03-30T22:50:26.822268Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Make predictions\nmodel_conv1D_preds = make_preds(conv1D_model, test_windows)\nmodel_conv1D_preds[:10]","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:50:31.949101Z","iopub.execute_input":"2022-03-30T22:50:31.949408Z","iopub.status.idle":"2022-03-30T22:50:34.244489Z","shell.execute_reply.started":"2022-03-30T22:50:31.949376Z","shell.execute_reply":"2022-03-30T22:50:34.243526Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Evaluate predictions\nmodel_conv1D_results = evaluate_preds(y_true=tf.squeeze(test_labels),\n                                 y_pred=model_conv1D_preds)\nmodel_conv1D_results","metadata":{"execution":{"iopub.status.busy":"2022-03-30T22:50:36.977439Z","iopub.execute_input":"2022-03-30T22:50:36.977722Z","iopub.status.idle":"2022-03-30T22:50:36.987721Z","shell.execute_reply.started":"2022-03-30T22:50:36.977694Z","shell.execute_reply":"2022-03-30T22:50:36.986871Z"},"trusted":true},"execution_count":41,"outputs":[]}]}